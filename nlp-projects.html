<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>NLP Projects | Bota Duisenbay</title>
  <link rel="stylesheet" href="style.css" />
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
</head>
<body>
  <header>
    <h1>Bota Duisenbay</h1>
    <nav>
      <ul>
        <li><a href="index.html">Home</a></li>
        <li><a href="projects.html" class="active">Projects</a></li>
        <li><a href="education.html">Education</a></li>
        <li><a href="publications.html">Publications</a></li>
        <li><a href="index.html#contact">Contact</a></li>
      </ul>
    </nav>
  </header>

  <main>
    <section>
      <h2>HW1: Named Entity Recognition (NER)</h2>
      <p>
        Built and evaluated multiple BiLSTM-based models using GloVe embeddings for NER with IOB tagging.  
        Preprocessing significantly improved performance by reducing unknown tokens.  
        Best F1 score: <strong>0.5387</strong> using 2-layer BiLSTM with 300-d embeddings and dropout.
      </p>
      <p>
        ðŸ”— <a href="https://github.com/botastark/NLP/tree/main/duisenbay_1849680_hw1" target="_blank">Project Code</a> | 
        ðŸ“„ <a href="https://github.com/botastark/NLP/blob/main/duisenbay_1849680_hw1/report.pdf" target="_blank">View Report (PDF)</a>
      </p>
    </section>

    <section>
      <h2>HW2: Semantic Role Labeling (SRL)</h2>
      <p>
        Implemented SRL using both GloVe and BERT embeddings.  
        Created a token-wise dataset per predicate with role classification.  
        Findings showed predicate indication method heavily influences performance.
      </p>
      <p>
        ðŸ”— <a href="https://github.com/botastark/NLP/tree/main/duisenbay_1849680_hw2" target="_blank">Project Code</a> | 
        ðŸ“„ <a href="https://github.com/botastark/NLP/blob/main/duisenbay_1849680_hw2/report.pdf" target="_blank">View Report (PDF)</a>
      </p>
    </section>

    <section>
      <h2>HW3: Coreference Resolution</h2>
      <p>
        Modeled pronoun resolution using ALBERT, BERT, and RoBERTa.  
        Best performance achieved by RoBERTa.  
        Tagged entity/pronoun positions for effective encoding.  
        Used binary classification on ProBERT features.
      </p>
      <p>
        ðŸ”— <a href="https://github.com/botastark/NLP/tree/main/duisenbay_1849680_hw3" target="_blank">Project Code</a> | 
        ðŸ“„ <a href="https://github.com/botastark/NLP/blob/main/duisenbay_1849680_hw3/NLP_HW3_report.pdf" target="_blank">View Report (PDF)</a>
      </p>
    </section>
  </main>

  <footer>
    <p>&copy; 2025 Bota Duisenbay. All rights reserved.</p>
  </footer>
</body>
</html>
