<section>
  <h2>HW1: Named Entity Recognition (NER)</h2>
  <p>
    Built and evaluated multiple BiLSTM-based models using GloVe embeddings for NER with IOB tagging.  
    Preprocessing significantly improved performance by reducing unknown tokens.  
    Best F1 score: <strong>0.5387</strong> using 2-layer BiLSTM with 300-d embeddings and dropout.
  </p>
  <p>
    ðŸ”— <a href="https://github.com/botastark/NLP/tree/main/duisenbay_1849680_hw1" target="_blank">Project Code</a> | 
    ðŸ“„ <a href="https://github.com/botastark/NLP/blob/main/duisenbay_1849680_hw1/NLP_HW1_report.pdf" target="_blank">View Report (PDF)</a>
  </p>
</section>

<section>
  <h2>HW2: Semantic Role Labeling (SRL)</h2>
  <p>
    Implemented SRL using both GloVe and BERT embeddings.  
    Created a token-wise dataset per predicate with role classification.  
    Findings showed predicate indication method heavily influences performance.
  </p>
  <p>
    ðŸ”— <a href="https://github.com/botastark/NLP/tree/main/duisenbay_1849680_hw2" target="_blank">Project Code</a> | 
    ðŸ“„ <a href="https://github.com/botastark/NLP/blob/main/duisenbay_1849680_hw2/NLP_HW2_report.pdf" target="_blank">View Report (PDF)</a>
  </p>
</section>

<section>
  <h2>HW3: Coreference Resolution</h2>
  <p>
    Modeled pronoun resolution using ALBERT, BERT, and RoBERTa.  
    Best performance achieved by RoBERTa.  
    Tagged entity/pronoun positions for effective encoding.  
    Used binary classification on ProBERT features.
  </p>
  <p>
    ðŸ”— <a href="https://github.com/botastark/NLP/tree/main/duisenbay_1849680_hw3" target="_blank">Project Code</a> | 
    ðŸ“„ <a href="https://github.com/botastark/NLP/blob/main/duisenbay_1849680_hw3/NLP_HW3_report.pdf" target="_blank">View Report (PDF)</a>
  </p>
</section>
